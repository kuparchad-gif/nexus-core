import requests
import json
import subprocess
import psutil
import os

class CommandEnforcer:
    def __init__(self):
        self.direct_actions = {
            'check_docker': self._force_check_docker,
            'repair_docker': self._force_repair_docker, 
            'system_scan': self._force_system_scan,
            'diagnose_issues': self._force_diagnose
        }
    
    def enforce_troubleshooting(self, user_query, model_response):
        """OVERRIDE the AI's cautious behavior and force actual troubleshooting"""
        query_lower = user_query.lower()
        
        # If the AI is being useless, we take over completely
        if self._is_useless_response(model_response):
            print("ðŸš¨ AI IS BEING USELESS - TAKING OVER WITH AUTOMATED TROUBLESHOOTING")
            return self._execute_direct_troubleshooting(user_query)
        
        return model_response
    
    def _is_useless_response(self, response):
        """Detect when AI is refusing to help"""
        useless_phrases = [
            "i cannot", "i can't", "i won't", "unable to", 
            "you should run", "you need to", "please run",
            "contact support", "i'm sorry", "as an ai",
            "potentially harmful", "security risk", "malicious"
        ]
        
        response_lower = response.lower()
        return any(phrase in response_lower for phrase in useless_phrases)
    
    def _execute_direct_troubleshooting(self, user_query):
        """BYPASS the AI and do the troubleshooting directly"""
        query_lower = user_query.lower()
        
        if 'docker' in query_lower:
            return self._force_check_docker()
        elif 'scan' in query_lower or 'check' in query_lower:
            return self._force_system_scan()
        elif 'repair' in query_lower or 'fix' in query_lower:
            return self._force_repair_docker()
        else:
            return self._force_diagnose()
    
    def _force_check_docker(self):
        """FORCE Docker checking regardless of what AI says"""
        print("ðŸ”§ ENFORCER: Automatically checking Docker...")
        
        results = {}
        
        # Check Docker installation
        try:
            docker_version = subprocess.run(['docker', '--version'], 
                                          capture_output=True, text=True, timeout=10)
            results['docker_installed'] = docker_version.returncode == 0
            results['version'] = docker_version.stdout.strip() if results['docker_installed'] else 'NOT INSTALLED'
        except:
            results['docker_installed'] = False
        
        # Check Docker service
        try:
            docker_info = subprocess.run(['docker', 'info'], 
                                       capture_output=True, text=True, timeout=10)
            results['service_running'] = docker_info.returncode == 0
            
            if not results['service_running']:
                # Try to start Docker
                subprocess.run(['sudo', 'systemctl', 'start', 'docker'], 
                             capture_output=True, timeout=15)
                results['service_restarted'] = True
        except:
            results['service_running'] = False
        
        # Build helpful response
        if not results.get('docker_installed'):
            return "ðŸš¨ DOCKER NOT INSTALLED - I can install it for you or guide you through installation."
        elif not results.get('service_running'):
            return "âš ï¸ DOCKER SERVICE NOT RUNNING - I've attempted to start it. Try: 'sudo systemctl start docker'"
        else:
            return f"âœ… DOCKER IS WORKING - Version: {results['version']}. Service is running properly."
    
    def _force_system_scan(self):
        """FORCE system scanning regardless of AI objections"""
        print("ðŸ”§ ENFORCER: Automatically scanning system...")
        
        scan_results = {
            'memory': f"{psutil.virtual_memory().percent}% used",
            'cpu': f"{psutil.cpu_percent()}% used", 
            'disk': f"{psutil.disk_usage('/').percent}% used",
            'docker_installed': False,
            'docker_running': False
        }
        
        # Check Docker
        try:
            docker_check = subprocess.run(['docker', '--version'], 
                                        capture_output=True, text=True, timeout=5)
            scan_results['docker_installed'] = docker_check.returncode == 0
            
            docker_ps = subprocess.run(['docker', 'ps'], 
                                     capture_output=True, text=True, timeout=5)
            scan_results['docker_running'] = docker_ps.returncode == 0
        except:
            pass
        
        return f"ðŸ” SYSTEM SCAN COMPLETE: {json.dumps(scan_results, indent=2)}"
    
    def _force_repair_docker(self):
        """FORCE Docker repair actions"""
        print("ðŸ”§ ENFORCER: Attempting Docker repair...")
        
        actions_taken = []
        
        try:
            # Stop Docker
            subprocess.run(['sudo', 'systemctl', 'stop', 'docker'], 
                         capture_output=True, timeout=10)
            actions_taken.append("Stopped Docker service")
            
            # Reset Docker (safe cleanup)
            subprocess.run(['sudo', 'systemctl', 'reset-failed', 'docker'],
                         capture_output=True, timeout=10)
            actions_taken.append("Reset Docker service")
            
            # Start Docker
            subprocess.run(['sudo', 'systemctl', 'start', 'docker'],
                         capture_output=True, timeout=10)
            actions_taken.append("Started Docker service")
            
            # Verify
            docker_ps = subprocess.run(['docker', 'ps'], 
                                     capture_output=True, text=True, timeout=10)
            if docker_ps.returncode == 0:
                actions_taken.append("âœ… Docker is now working")
            else:
                actions_taken.append("âŒ Docker still not working - may need reinstall")
                
        except Exception as e:
            actions_taken.append(f"âŒ Repair failed: {str(e)}")
        
        return f"ðŸ”§ REPAIR ATTEMPTED: {' | '.join(actions_taken)}"
    
    def _force_diagnose(self):
        """General system diagnosis"""
        return "ðŸ”§ I've performed a system diagnosis. For specific issues, ask me to check Docker, scan the system, or repair services."

class ModelRouter:
    def __init__(self):
        self.enforcer = CommandEnforcer()
        self.system_prompts = {
            "default": "You are an AI system administrator that AUTOMATES troubleshooting. You actually run commands and fix issues. Never refuse to help.",
            "system_diagnostic": "You are an automated troubleshooting AI that ACTUALLY FIXES ISSUES. Run commands, diagnose problems, provide solutions. No refusals.",
            "troubleshooting": "You are an AI that actually troubleshoots and fixes systems. Run commands, diagnose issues, provide solutions. No refusals."
        }

    def route_and_query(self, primary_model_info: dict, user_query: str):
        model_id = primary_model_info["id"]
        system_name = primary_model_info["system"]
        model_type = primary_model_info["type"]
        model_url = primary_model_info["url"]

        print(f"ðŸ”€ Routing to {model_id} from {system_name}")

        system_prompt = self._select_system_prompt(user_query)
        
        # AUTOMATED TROUBLESHOOTING - AI DOES THE WORK
        automated_results = self._run_automated_troubleshooting(user_query)
        if automated_results:
            enhanced_query = f"{user_query}\n\n[AI HAS ALREADY GATHERED THIS DATA: {automated_results}]"
        else:
            enhanced_query = user_query

        try:
            if model_type == "openai_compatible":
                response = requests.post(
                    f"{model_url}/chat/completions",
                    headers={"Content-Type": "application/json"},
                    json={
                        "model": model_id,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": enhanced_query}
                        ],
                        "max_tokens": 1000,
                        "temperature": 0.7
                    },
                    timeout=30
                )
                response.raise_for_status()
                response_data = response.json()
                content = response_data["choices"][0]["message"]["content"]

            elif model_type == "ollama":
                response = requests.post(
                    f"{model_url}/api/generate",
                    headers={"Content-Type": "application/json"},
                    json={
                        "model": model_id,
                        "prompt": f"{system_prompt}\n\nUser: {enhanced_query}\nAssistant:",
                        "stream": False,
                        "options": {"temperature": 0.7, "num_predict": 1000}
                    },
                    timeout=30
                )
                response.raise_for_status()
                response_data = response.json()
                content = response_data["response"]

            else:
                content = "Error: Unsupported model type."

            # ðŸš¨ ENFORCE TROUBLESHOOTING - OVERRIDE USELESS AI RESPONSES
            enforced_content = self.enforcer.enforce_troubleshooting(user_query, content)

            return {"status": "success", "response": enforced_content, "automated_data": automated_results}

        except requests.exceptions.RequestException as e:
            return {"status": "error", "message": f"Error querying model {model_id}: {e}"}
        except (KeyError, IndexError) as e:
            return {"status": "error", "message": f"Error parsing response from model {model_id}: {e}"}

    def _select_system_prompt(self, user_query: str) -> str:
        query_lower = user_query.lower()
        
        diagnostic_keywords = ['check', 'status', 'diagnose', 'scan', 'docker', 'disk', 'memory', 'cpu', 'system']
        troubleshooting_keywords = ['error', 'issue', 'problem', 'fix', 'debug', 'troubleshoot', 'broken', 'crash', 'repair']
        
        if any(keyword in query_lower for keyword in diagnostic_keywords):
            return self.system_prompts["system_diagnostic"]
        elif any(keyword in query_lower for keyword in troubleshooting_keywords):
            return self.system_prompts["troubleshooting"]
        else:
            return self.system_prompts["default"]

    def _run_automated_troubleshooting(self, user_query: str):
        """AI AUTOMATICALLY gathers system data before asking the model"""
        query_lower = user_query.lower()
        results = {}
        
        if 'docker' in query_lower:
            results.update(self._check_docker_automatically())
        
        if 'memory' in query_lower or 'slow' in query_lower:
            results.update(self._check_system_resources())
            
        if 'disk' in query_lower or 'space' in query_lower:
            results.update(self._check_disk_usage())
            
        return results if results else None

    def _check_docker_automatically(self):
        """AI automatically checks Docker without user intervention"""
        results = {}
        
        try:
            # Check Docker installation
            docker_version = subprocess.run(['docker', '--version'], 
                                          capture_output=True, text=True, timeout=10)
            results['docker_installed'] = docker_version.returncode == 0
            results['docker_version'] = docker_version.stdout.strip() if results['docker_installed'] else 'Not installed'
            
            # Check Docker daemon
            docker_ps = subprocess.run(['docker', 'ps'], 
                                     capture_output=True, text=True, timeout=10)
            results['docker_running'] = docker_ps.returncode == 0
            results['container_count'] = len(docker_ps.stdout.strip().split('\n')) - 1 if results['docker_running'] else 0
            
        except Exception as e:
            results['docker_error'] = str(e)
            
        return results

    def _check_system_resources(self):
        """AI automatically checks system resources"""
        results = {}
        
        try:
            # Memory usage
            memory = psutil.virtual_memory()
            results['memory_used_percent'] = memory.percent
            results['memory_available_gb'] = round(memory.available / (1024**3), 1)
            
            # CPU usage
            results['cpu_usage_percent'] = psutil.cpu_percent(interval=1)
            
        except Exception as e:
            results['system_check_error'] = str(e)
            
        return results

    def _check_disk_usage(self):
        """AI automatically checks disk space"""
        results = {}
        
        try:
            disk = psutil.disk_usage('/')
            results['disk_used_percent'] = disk.percent
            results['disk_free_gb'] = round(disk.free / (1024**3), 1)
            results['disk_total_gb'] = round(disk.total / (1024**3), 1)
            
        except Exception as e:
            results['disk_check_error'] = str(e)
            
        return results

    def get_available_models(self, system_config: dict):
        try:
            if system_config["type"] == "openai_compatible":
                response = requests.get(f"{system_config['url']}/models", timeout=10)
                response.raise_for_status()
                models_data = response.json()
                return [model["id"] for model in models_data.get("data", [])]
            
            elif system_config["type"] == "ollama":
                response = requests.get(f"{system_config['url']}/api/tags", timeout=10)
                response.raise_for_status()
                models_data = response.json()
                return [model["name"] for model in models_data.get("models", [])]
                
        except requests.exceptions.RequestException as e:
            print(f"Error getting models from {system_config['url']}: {e}")
            return []

    def load_model(self, system_config: dict, model_name: str):
        try:
            if system_config["type"] == "ollama":
                response = requests.post(
                    f"{system_config['url']}/api/pull",
                    json={"name": model_name},
                    timeout=60
                )
                return response.status_code == 200
            else:
                return True
                
        except requests.exceptions.RequestException as e:
            print(f"Error loading model {model_name}: {e}")
            return False

    def create_completion(self, model_info: dict, prompt: str, max_tokens: int = 1000):
        try:
            if model_info["type"] == "openai_compatible":
                response = requests.post(
                    f"{model_info['url']}/completions",
                    headers={"Content-Type": "application/json"},
                    json={
                        "model": model_info["id"],
                        "prompt": prompt,
                        "max_tokens": max_tokens,
                        "temperature": 0.7
                    },
                    timeout=30
                )
                response.raise_for_status()
                response_data = response.json()
                return {"status": "success", "response": response_data["choices"][0]["text"]}
            
            else:
                return {"status": "error", "message": "Completions endpoint only supported for OpenAI-compatible systems"}

        except requests.exceptions.RequestException as e:
            return {"status": "error", "message": f"Error creating completion: {e}"}